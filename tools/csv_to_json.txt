#!/bin/sh
# Moved script to .txt file to discourage use.
#
# Script (and/or notes) for prepping the big Reviews.csv
# from https://www.kaggle.com/snap/amazon-fine-food-reviews
# into many JSON files to upload into Discovery.
#
# It was a hacky process, but here are the notes.
#
# This creates many, many files so you probably don't want
# to try it. You should filter the .csv file first.

# Run from tools/ but process files in ../data/
cd ../data/

# Pre-req:
#
# Install csvtojson cli with "npm i -g csvtojson"
# See https://www.npmjs.com/package/csvtojson

# Use csvtojson to convert csv to 1 big JSON.
# Use split to create 1 json file per CSV row.

csvtojson Reviews.csv | split -l 1 -a 5 - review_

# slap a .json suffix on the split results

for f in review*; do mv "$f" "$f".json; done

# Note: the first and last file is bad. Just contains '['.
rm review_aaaaa.json

# Since there is too much data for a trial, move the files
# we want to keep into data/food_reviews.
mkdir -p food_reviews
cp review_aaaa*.json food_reviews/

# Remove trailing comma in each JSON file.
sed -i '' 's/,$//' food_reviews/*.json

